{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banana_Data  Banana.x86  Banana.x86_64\r\n"
     ]
    }
   ],
   "source": [
    "!ls Banana_Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Banana_Linux_NoVis/Banana.x86_64\")\n",
    "\n",
    "# To run the visual environment uncomment the next line\n",
    "#env = UnityEnvironment(file_name=\"./Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            \n",
    "action = np.random.randint(action_size)        # select an action\n",
    "next_state = env.step(action)['BananaBrain']\n",
    "print(next_state.vector_observations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Networkr architecture\n",
    "\n",
    "Below a neural network's architecture it's definded. Let's see how it is the output after a forward pass of the environment's state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self,sate_size, action_size, seed, hidden_layers, p):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Set random seed\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        # Define input and output for each hidden layer\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        # Create ModuleList and add input layer\n",
    "        self.hl = nn.ModuleList([nn.Linear(state_size, hidden_layers[0])])\n",
    "        # Add hidden layers to the ModuleList\n",
    "        self.hl.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        # Add output layer\n",
    "        self.output = nn.Linear(hidden_layers[-1], action_size)\n",
    "        # Add the probability for a node to be dropped at each layer\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for linear in self.hl:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "                \n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(37,4,0,[54,16],.1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]\n",
    "state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "state\n",
    "#model.forward(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 1.11\n",
      "Episode 200\tAverage Score: 5.00\n",
      "Episode 300\tAverage Score: 7.93\n",
      "Episode 400\tAverage Score: 8.48\n",
      "Episode 500\tAverage Score: 9.84\n",
      "Episode 600\tAverage Score: 12.44\n",
      "Episode 620\tAverage Score: 13.03\n",
      "Environment solved in 520 episodes!\tAverage Score: 13.03\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABRi0lEQVR4nO2deZgcVbn/v2/3rNn3BRIyCQlgWAIhgiwhsi9RcUFckasooqByLypxx4sXUS+gCD8WlwteuICIIhgEkhBIkHWykoTsZN/3zGRmMtN9fn9UnepTp05t3dXT09Pv53nm6elaT1VXve95l/MeEkKAYRiGqTxSpW4AwzAMUxpYATAMw1QorAAYhmEqFFYADMMwFQorAIZhmAqlqtQNiMOgQYNEQ0NDqZvBMAxTVsybN2+XEGKwvrysFEBDQwMaGxtL3QyGYZiygojWm5azC4hhGKZCYQXAMAxTobACYBiGqVBYATAMw1QorAAYhmEqFFYADMMwFQorAIZhmAqFFQDDMGXNoo37sGTz/lI3oywpq4FgDMMwOpff+y8AwLrbp5a4JeUHWwAMwzAVCisAhmGYCoUVAMMwTIXCCoBhGKZCYQXAMAxTobACYBiGqVBYATAMwyTElx9uxF0zVpa6GZFhBcAwDJMQM9/djt/MWlXqZkSGFQDDMEyFwgqAYRimQmEFwDAMU6EUXQEQ0Ugimk1Ey4hoKRF9y14+gIhmENEq+7N/sdvCMAzD5OgMC6ADwE1CiPEAPgDgeiIaD2AagFlCiHEAZtnfGYZhmE6i6ApACLFVCDHf/v8ggHcBHAngcgAP25s9DOCjxW4LwzBMubH/UDtmLtuOXU1tiR+7U2MARNQA4BQAbwIYKoTYaq/aBmCozz7XElEjETXu3LmzcxrKMAzTRVi9swlf/lNjUeY86DQFQES9ADwF4EYhxAF1nRBCABCm/YQQDwohJgkhJg0ePLgTWsowDNN1yApLNKZTlPixO0UBEFE1LOH/qBDir/bi7UQ03F4/HMCOzmgLwzBMOZHJ2gqAylABEBEB+AOAd4UQdyqrngFwtf3/1QD+Xuy2MAzDlBuOAiiCBdAZU0KeBeAqAO8Q0UJ72fcB3A7gz0R0DYD1AK7shLYwDMOUFWWtAIQQrwLwa/n5xT4/wzBMOZOxYwCpco0BMAzDMPmRyVgKoIoVAMMwTHIIIXDnjJVYtf1grP2a2zpwyzNL0XI44yz789sbA/dZuf0gfjPTXCk0mxX4+XPvYtPeQ551jgVQjkFghmGYrkrz4QzunrUKVz7weqz97nt5DR56bR0efn2ds+y7Ty0O3OeT97+Ou2auRHNbh2fd4s378cCctfj3JxZ61mWLGANgBcAwTMUiRWqz0pOPQns2CyCXox+Fwx3WPqaOvFyXNRxOWgDsAmIYhkkQKcDbM9m89iff/BZ/TDqjwz5/ddp7PJkFxEFghmGYBLE78kahHIi9fT5ueZPV0GEL+eq0VySX9UAwhmGYrkocF46K3CsfkWxy83TYmsjk5y/mOABWAAzDVCyZfBWAvV9eFoBBAxzuiGABsAJgGIZJjrwtAOkCysMGMLuAAmIA5V4MjmF0Xlm5Ew3TpuPdrQfCN2YisXjTPjRMm47X1uwqdVMK4sbHF6Bh2vROOZcqixumTcd9L68J3WfyL1/C7199L3CbhmnTcc1DbwMA7p29Gg3TpqOl3co0MrqAMlLIWyL5yvtfd+4Bp4Ey3Y4Xl24DADSu31vilnQf3li7GwAwe3l5F9Z9euGWTjtXRpPGj765PnSfjXtanP+DXECz7N/hT8pYAcBsARyWWUC2kH9r3R5nXQcHgZluS54mOONFuiNMPUzGTL4uoKTP2WaPA6jiNFCmEpCdGZZVyVGEDmK3p1D5T3ncdJOCbrPdQ1WGIHCWB4Ix3RU2AJKH72l0dBdQMdB/D1MWkLQAqg1CvoNjAEx3Qxa2EiytEkP2Rkvh1ihX9HsVt0Of3zgAgwKwLQAZBHZtL11AHANgugvsrUieSrynhXYg9M543LTOKDJZ38ZkdbR1+NcWklUq2AXEdDu4r2rx6qpd2LjHWwo4Dk5cRQh0ZLJ4at4mo7shaZZtOYDFm/YV/Twm4sr/Pc2H8YKdgQYUbi0VOhJ4095DmLtqp6MAOrJZrNnZ5No+Y48RKEYQuDOmhGQYD/kEz7ozn//Dm6ipSmHlzy7N+xjyjgoAv5v7Hn7x/HIIAFecOiKJJvpy2d1zAQDrbp+a6HGFEKHPSVwB/pU/NWLe+r1Y+OML0a9HTeEKII/nWLVazvvvV3A4k8VnTjsKgNXbP/+OV5z1maxARoii+P8BtgCYEsPu6hyyJHC+yB6iEMCupjYAwL5DhwtuV6mIEqCN+/is29UMAGi3B15lC7vleWVeqeUnZP6/tNR0i609k0UmW5wAMMAKgGG6DTkLoHto1Sjeq3x78FJwJ+UCihOLMCkd2Y4O7aI7sgKZbLYog8AAVgBMiekeoqpr0V2sqijCudBrTSpjKs5hTOeUcl9f197BFgDTDeEQQPJIf7QqQspZGRRDAeib626msOfS09O3d4hTVdSsAISxPe3ZLLIcA2C6KzwOILl7kMsC6h4pocV0AcU5h4pHYeTRDtM5fRVARqAjm2UFwHQv8imj211JPlNTKP+Vr4KNZAEUeOy4ylcGjyWq0o17bhUp+HUF0GEHgYsxCAxgBcAwibNtfytO+6+ZWKvlc/vRUWgqik1udHWwK+Oah97G7+asTeSc+fDyih04746XQ7Oe9IyYX89ciW88tsC9TYDknb9hLyb/8iUcbG13lkmBf/Fdc/D0gs244v7XQ9v765kr8a3HrfO2a7+V7Mj4ZSxd9Yc3sf1Am7vN9rat7bmJ6GU56OeVMQoAMOVXL2PZ1gNFGQQGsAJgSkR3jgH8Y/EW7DjYhkfe2BBp+4Tkv9EdYZKPs5bvwH89924yJ82DHz69BGt3NmP7gdbA7XSZ+uuZq/DsInepaBFw7+54cQU27mnBwo37POv2HmrHjU8sjNTeX89chb/bJarbNaUVlk00d5V3bgZ5XW3KsYImpV+0cR+7gJjuCYcA8p+WUMcVA+gGGjbaOAD/barsujp6amUh6MdylG4MJZ4x5Py3h7TRUCIoEVgBMCWhu+Wsm4h6bZlMQgoAhiygRI5cGqL454PkpnSbdMS4v2Fq089tFScILK9LVSYdARYAkFNmScMKgCkJ+QTPuitJWQDgLCAXcoL1IPdKXHQLQH7LJwtI3SdMSRXJA1R8BUBEfySiHUS0RFl2CxFtJqKF9t9lxW4H07XoDi6KpEiqJr0TBC7jfr/a64+iGIM2kbNrqUI77Ihhz6WuTOT54yjxjCHlUw8u65RzDOAhAJcYlt8lhDjZ/nuuE9rBdEHKV1T5E1e5JTUa1TlrGd9UVShGqWQa5CbKuYCSsQAyWeFRALl00ujHMeX8h1kApnkCkqDoCkAIMQfAntANmW7Pqu0HnRe2O/f/TUJJCIFV2w8aty+0DLTnXK7zRtuntT2DDbv927G/pR2vrd6F9kwWq3ccNArn3U1thj3jsWZns/N/WNtXbT/ochPtaXYXvkvCBbR6Ry6Vt60jg3e3un/DfFxA6+2CdC4LIKSNhpkiE6GUMYAbiGix7SLq77cREV1LRI1E1Lhz587ObB+TILOX78CFd83B0ws3u5ZXSgzgkTfW48K75uDNtbs966LkokdBdhJFQBDAr1f9708sxDm/mo22joxx/X8+uwyf/f2b+O2sVbjgzjm4d/Zqzzan/mxmrPbqQrO5rQMX/3qO8z3IrSKfp78u2OQsm3jrDNc2VY4CCE6L9WPFtoO44M5caeaZ7+7At59c5NpGGHrzYdzy7DIIIVzXF5ap1N2CwPcBOBrAyQC2ArjDb0MhxINCiElCiEmDBw/upOYxSbPC7v06PahubAKYXEAL7Fz0DQn39l3nNWYBaSNLfQTN7BU7APinM8qc/Y17WwAAc1d789vjojdFHRhlrfcXisu3ac+TAekCiiOc1V9u6/4W17plWw54tpdNjNuRyWRFLAugd11xpm4piQIQQmwXQmSEEFkAvwNwWinawZSecg5YxkH2vIsVzFOxDADzefxGHUcVYD1q0gCAptaOvNqmEiaYg2IA0q8fdDtlEFgVrnFKP+i/la6gAP8aPmFkhIgVA+hTXx3r+FEpiQIgouHK148BWOK3LdM9qbRaQPL91oWKGqAsNDFKKtOgkcB+FoBwPsPSEa1GNrUVrgDChHGQTJXXEVQnv8Z2AbXlOdGOXn/HdBx5CXED+ULEiwH0LZICKPqUkET0GIAPAhhERJsA/ATAB4noZFjP3ToAXy12O5iugf66VkoMQPZmdaFyWFUABZ7DcUfAX5mEDToL+z2k4E1CAYR1moOEqhSeQfPkynXJKQB/CyCfqqIuCyDkAGWrAIQQnzEs/kOxz8t0bSphGIAqvzI+LqDW9pxwKrTio8h1433xFTQRe7JygvIkFIDuNtGbFuRWkXnzQRaAVLptiusmjpzWf6u2dn9FEtcCyGhB4DALoE9dN3IBMUylIV92j1BRepVBvdkoODnpAWLOT6jm3EfB55C+6kLnL7bOpY2q9Xz331daMkE6U15rvhaAnnoZFAOIqwCyWeGuBVQiFxArAKZT8EyklOdx7p292pNPn80K/OL55di237+65D/f2YoXtFK7xUYVThkfn3WbywJw779sywE88MqaSOdq68jg1n8sAwA89842tBw2p3OGlp72kWOy2XEKq/11/ia8sjKXuv3IG+vxzccWYJOdSfT7uWvx1/mbcM9LqwAAv5m1ytPWXzy/HFv2ubNxgJxCffztjZ51u5vacNtz7zrutYdeW4e318UfihTkrpPc9txy3PTnRWhuM99vP+6etdrJZALclqCJPvXFcdYU3QXEMC40IRcnK6O1PYNfvbACD85Zi0U/uchZvmDjPtz38hos2LAXj197hnHfrz06HwCw7vap8ducJ1FcQGrvVBc4U387F0IAX51ydOi5/ty4CQeUzJyHXltn3M7XAojqAorxe/3Hn62ceXnPf/i0O9fj6YVb8LRdZvnK94/Eo2+6y2e/s3k/7nt5DRrX7cGT153pbkeAIvrx35di+jtbcWS/emfZJ+9/3WpHWPOVnyCqC+ip+ZswcVS/kAO7+eO/3ou1PVsATLeikJmU9GCcXK7P1lQqTNaNbKPuslDdCroCcOrMROh1Z3xcCLqC9btHUUe05ltWIUzRm9olr7vF4HoJ+q3l9oWW2NB/j6B6PXEqjvpx8fFDcdOFxxjXcQyA6VaYBi2FId9nPYU0t7xrYLomKcz0daoF4OfPjlLKIGr9oTBlEvZ76PtHteDCgsZtBiEvr8h0+ZkAYZxUcT1PCm2AkE+i4miKyBm9rMMWAFPW6IHJfBJe5BH0fYVP77orYZoEBHBbM3rz5fUUIly84wCCLYVQC8CjAKK140DIwDFTL9+xSvRsoawIjEUEFWiL4QHyPLNBv0MSk86kiHynfuxWA8GYysWv9x4Fx42iLXcUQxexAYJcQN7yB0oMQHv540xoois/33EAYQPBQk6l7x81JrD/UHvgelOGjcw00s+RFSLwnhTLAjAFgSVJVBxNpch3pHif7lQKgmHymRHMbzCV56BdECmUdOGkWgB6hpAUBvlYAPJY+t31HQks3J9+6II3qrA90BqsAA4Zspake0y3APQyCjqJKQDte9DvkFT8SZav8C7vXsXgmAonF3SMvk8219UvOzKOgNUUQLsaA9AtALuaZR4CzW9MQWj9nVAXkLkefhj7W/JRAOZgrhDBwthvPMSB1vbQmIX6G+jnDRoIlkQMQAjRKbWiVFgBMIH8z7/eQ8O06aEvcBj6eyd8BGIQvi4g+xBvvbcHDdOm59lCfzoyWTRMm447X1yR1/6n3zYTi+xqoFkBPLtoCxqmTcemvYe0NFCgYdp0/PDpd5zvANBuGMi0eV8LGqZNxzOLrDRK/Z7IfeW9OfaH/8SnH3w91J2UFQK3PLMUDdOm4+a/LPbcT92CiKqbDobEAEwuoHtnW2Mg1u0+5GpHVghfd8yJP3kBb6/bCwDYfsA9P8FJt7yIZp/xETpb97fg4//vNdcyU5xCkoTVIQR8YwDFghUAE8j/vr4eALDzYOGTfajkM4JSugL0nnKxK4pKYfPg3LV57a8KoowQ+NsCa06E5VsPurJZpGvrkTesfHhp9psCt7I08dP2sXSnv2fAWUcWb6zdEzoQTIjcGIInGr2DrDzumIiCL8xHbrIA/Mhk/WMABxMoUQEAizft9ywLtgAKfwazQjgzf/XrUY1ZN03Bg1edihduPKfgY/vBA8GYQORjnXTHpBAXkCcE4LEuRKJzDjspqwnoGSFErncOtwDV77F0Bxzu8J5YKk6/eIjf8rBslbBr1AVdlGkbgfDf2W/kst+xkvLz+2GyWIKCwEm4gLJCOBbA5HGDcfTgXjh6cK+CjxsEWwBMIGGCJi7yMHlZACFZQJIgU73UWNdAzv+qPPXGAOSk5qYyxPJ3sffV1vvGACK4gILINwso7LhxfjN9Nq1icDAkaK0TWmIjAlmR+93iuEYLgRUAE4jfCNaCiZh1opLxcQHpFBqv0MkFFQsnk1X98yKwBx2UBSQX+QUNc1aG+/ihFkDg2vyDwGHbHToc3XWjl1IuBmExC50kXEAu67Bz5D8rACYY+b4nZQE4x5UWQIwXOeqI3wMtyfiBnfN6/gkm6FZlhXDuZVbok7e4T1DlKID4LiA/Cs0C8pRwjtjxDfudWw5H70EX0wUk7+aBmJ2IJMYBqDO5FVrGIiqsAJhAoo4QjX9c2MeNvk/GxxrRm1Y8CyBaY4NuVTYrlMnb3S4U3a2RCrAAHAVgb6PfE6f0hNaW8CBwWBpovi6g4PUt7dGVdlaIogvI2BZAAgopK0ReNbIKgRVAN+X5JVsjT9rRnsni7ws3G1/+bB6COggpp3LHjR8D0G0AT753gALQr7XlcAbTF28NPK88bXtG4P+9vBozl20HYJWY1u/xqu0H8c5mK4Nk2dYDWLrFnU2SFTkXVlZzAemZLVVRFICPAeD3ezkzaZGlKJ9s3IgZ9vWo1+qH3sboQeAwCyBOEDh4JHChPL9kK7Ye8C8tbsKUqhuXrMhvgGQhcBZQN2TV9oO47pH5mHricNz7uYmh29/z0mr8ZtYq1KRTuPTE4a51pnlm88Ez2Ucex/Wr+aMfojnAn3z/y2twx4yVSBHhwxOOwC3PLMUTjRsxvN+ZmHhU/9C2//L5FehdV4W/XHcmvvbofHzopOG457O5e3zhXXOc/996bw+m3v2q61huF5BwFTob3LsWu5sPO99lSqC5Uqa9jX0svQyGGrcwTTySIsI3HluAOUq9fmu/4Ov3WAARFUDYzxwnCKy7zpJk7a5mXPfI/Nj7mZT0l84aHavsM1sATCLIXummvYcibb/d7u3sNdRrcXrqCftccy6g6MfNOPEI7VjadkHH3NVk5eTLcQ2b9ln3qCnA5NcPl80KNLVZ92qzYbKSILJC5Hp5iiA7Y8xA1FWnXdtGsQD8AuKuCccVt48ceFadTmHdrmbf47qX5ZbrVTiTCgLHmWEsW8QgcNTjrv6vS13fTbOOfXzikfjGeWNdy/78VfN8FYAdA1DiQ50BK4BuiOMoSSBwm4+vPtpxpQUQfZ9cGmjwdQW5uau1wVXyWGGBW+8y6zNuEDabzWV6SF82EZBKea0kmeFjcndIhSxLxPjFAAC3BSEHM9VUmV99k5zOCuEs944ETiYGECeLJtsJaaBh6LV5TApACO/zEVTSR0AoTzYHgZk80XPEwwiSYUkHgXPjANzHj0LUlNSgtsoXN47A8VoYamG6yIdx9lWzgDJZgTQRUkQeoSYtANMApDAFpB5LzVCR1mF1OmX0M5uVXU4BeMYBRM0CCrMAYmTRdMZAMJ2BPWsC1+uTFAHWb6CXdgjqlGWzud+TXUBM3uRGzBZuAeRM/4RdQDIGECN2Jrf11gLS4wv6frkl1en4FTZ14aX2QGNbAMooZTmgSWby6E0KsgCc8/toIKfJwl03R1blTFF0ISNE7vfKtxpomKKP4wLqjHEAOgN7BSsA05y+WeW3leglOvTt9YGSxYYVQDckar68Zz9jj9B9zKQoJAvIWwvIjS5sOlwKwHYBxckiEd6v8hT5KQDZTusvTQQi8sRZqgKUlZwCMhcE9ke9VjlGQr0GvX2mZbJpahqpiJGOGe4Ciq4AwgbQFYP+PeJbAEJ4B+oFVfsUUCyA+E3MC1YA3ZD4g4SCeyXqZ77ou+cTW/Btgx6k9Xz3KoB4FoB2OkXwpWK+QZYLKNeujB0TSJE3pz6XBeRta4fmgvL7qYW2v7QA/Hrkpt8jK+DcY3V9nGycsO3i/h5JzMAVB7+YicRUKE4YXEBB76QQwnkVO+vyOA20G+KTLl/QsZIKuuUKqwnXJwAs2bwf33xsAb5yzhh85rSjPPv6xQB0y0UXNhmDCyiqz/n5JVtx23PLteObffC/nbUq9HhLNu/HP+xxB43r9+Iv8zahOm3dFb1XK+cGac8ItHVkcPk9/8KPPzQeZ44d5LT/4dfXo6ktg9NGm1NYf/vSaqxVsn3kIDk/ATN98RbPsim/nI29hw57lksFpnLBna9g9Y4m3HBuLvvl/lfWhAq0OC6gi389J3yjhKkJmZBFn9tZCMs9pwv8oA5DVgC19nl61qT9N0wQtgC6IVIgJlG8wSSok8CUBrp0y36s3dWMJw1liK1trc/wILD7eyEuoOsemY8Ne9zptKoLQn3B75ixMvR4/1AGnf1l3iYAloAnIo/iUscLrN99CMu3HcSPn1nqaf9T8zcFZkapA90OOArA7L753dz3PMt2Nx/2sQy8CmD1jiYAwD2zVzvLbv/n8tgxgC+dNRoPXnUq7vrUBN99xgzqiX87swGTxw0KPLYfF7xvaKTtrptyNHrU5vrKf7h6kmcbOZ/Bty86Bm99/wJ85+JjccrIfuihCXI1BvBvZzbg9o+fiEtPGAbAup8fGDMQ37n4WNz2sRNjX08+sALohuTrnzb7hK3PBEqdaMeVriXvufxGMGcMQteELmzUnrX0qxdSvTEr1AFVeR/GBcHfyspmFZeTYxX4t79vwATijgJIaAKTqJZU3Cyg66aMwUXHD8PHThnhu885xwzGLR85HlOOGey7zckj+/mu+8IZowLbJPnQScPRt95SABe8byjONyiOto4satIp3HDeOAzuXYvrzx0LIvL8FmpQ+JaPHI9Pn3YUvnLOGAC2ezBFuP7csegfknWUFKwAuiFx/dOBaaBJjQT2+a4eVwp4v0FZYTOC+X1XBauUe6Ya+3GQaaTJlckm34woAXiK8gWlsQYFGqULSAagCyFOSYYwPaFbAFEy2OR15nsdcX66PnWWIO9T7+81rzbM59tHUwCmLKCUmhXQybAC6IbksoASSAO138uk09KcUgXCu8xvVie/JgQFfQF3DED2fAudwONwxjL5/dIw40LkTalUUwL1wL6n/UozghSAnBIxK0TB9WZUSyiMMBeQrtCizI0rA6z5XkdU5Z1SevJBUzaaJm73WABGBWB9dnJc2zp31A2JqJ6Ijo17AiL6IxHtIKIlyrIBRDSDiFbZn+YIFpMXTgw4pmwyPX+5ss0FNcn3ZEYLIKYLyJunb95P/V93AcXVb7LHqtb2LwSC9zrUTCndqgsqPxyUay5JQthkhYg8oC6uCyjKNURRvkGHiZwjR0DP2vB8mWqDApCWg8RklXd2CWiVSAqAiD4MYCGA5+3vJxPRMxHP8RCAS7Rl0wDMEkKMAzDL/s4kRFidGJ2grUyumkIImhFMHXNgrkzqmDbuNnoEZ4AFYK/TXUBxry6nAKzGxJnT1gSRecAZINNO4Trf4Yz/NUfpPauje/NFZKNbAGEKR7d+orgvpZIIuo6gdZHfDwpRJPY6kwtItwBMv00JPUCRLYBbAJwGYB8ACCEWAhgdZUchxBwAe7TFlwN42P7/YQAfjdgOJgpmOZkXqqBu68hg455oBeY8TdL99Pbnks0HcudShIBJoKry/9DhDqzZ2YSt+1s8wmXfoXbXJPZuJWP9v3V/C1bvaHLy4rftb8G+Q4fxxtrdWL2jKXSGqjZFARxobXeyX/IlReQSgq3tGafQnJpts3HPIXRkslhil5zW2wNEUwDW6N7CWL3zIFZuPxhp27gdiCjuGWf6xFhHVs8RbbswV6psq8kC6FXnthyCYgClsACijgNoF0Ls1zRmIa0dKoSQuWnbAPjmYxHRtQCuBYCjjvLmhjNe1JrvsTA8gGq65neeXIxnFm3B8lsv8VSujIuUdZv3tWDtziaMGdzLFaw90NruMbvVKSE///s3MX/DPgDAPZ89xbXdPbNX457Zq7Hu9qkA3GmgssO6dMsBXHDnK87ym596Bzc/9Y7zfcKIvvj7DWf7tl8KXCLg3F+97CrjnA96DODrj87Hyu2WUlF97XsPtePbTy5y5hyQqPX09bRVE0lYAJ+47/XI28Y9V6wYgHLsdIoil4lQ5dkZYwbi9bW7jdulCDhuWB8AwOmjB3rbSoQMhJNh5lqnXMfZYwcZrY5Bva2Mnw8eOyRSu5MkqgWwlIg+CyBNROOI6LcAXkuiAcKyXX1/MSHEg0KISUKISYMH+6d7MTk6fHzlhZDNArOX7wBgrnwYF9VlIX3+rgqWhiwdNQtICn99PxNZgwsojEWb9gemSqouoEKFP2D1MtWmvWTfa8AScKqrZea7O6BjqkWjcmS/etf3bPBrlzjFsADShiDwlZNGYuZ/nON8Vw8zdkgv/PXrZyrnyK37ny++HyP6u++ReoxTR/XH6987D5841ZuWKt1VfoPF5v/oQrz+vfPwh3+bZFRsQ3rX4a3vn4/vXBw7xFowURXANwAcD6ANwP8B2A/gxgLOu52IhgOA/el9opm8KcZE7lllmHohyEO4s3/kMkUBGKLOfgPBwqbvc027GCP6GVRuQAYto/RUo0CGUhASoaVbmoRp2IQqxx/Rx/U9KzrX5xxXAcS5r24LADhCUXbquhQBE0b0c76rz1FdddozaCuHteHwvmYFId06JgsAAAb0rMHwvvWorUr7BreH9KlL7FmKQ6gLiIjSAKYLIc4F8IOEzvsMgKsB3G5//j2h4zJwu0qi4AShArZxvcB5CA49VU/9LturxhMDJ0HRNNE+Q5kClTDh6UeQspC1X5J6ZYn8XRdZ4a7oabqE1hAFYBJunelzjpt1FEUWmhIFCN7yC7nt3cfV3w+/jkTYaxQUA/Bs28US70ObI4TIAMgSUd98TkBEjwF4HcCxRLSJiK6BJfgvJKJVAC6wvzMJ4SiABI+ZVQyAJASH2sF3Sk4rxzVOguJj2ewzzGRm2s86bxwLwN+tIscBJFcjyf++ZoX7fpjy3sMUQHU65Slo1pklleOmyUbpvJhmq7MK6/nvqx5X38pvAGKYO0oGo6sjSPck3bJJEDUI3ATgHSKaAcCpLCWE+GbYjkKIz/isOj/iuZmY5CyAZI8pX54khJ7JAlBfZFOJAT/LxjSVpWk/IF7bg0a5yhhAUkLUSgM1r7Py7YMtgDAXUFWaUFuVco247cyBR4mPI4GSJqssswqw5b6rj4p+ubow9huAGPYaSddNdVX0uEVXIaoC+Kv9x5QBGR9XiR9RtnNNVlGI5DDMeSqPF2YB+AwDwP6WYBeQKqTjlBEOjAHYgrTZR2jERU8DVdGDwPm4gNIpQm1VGgeRa29nWgDFcDeZmp8icglZl+dSa0PUDlJUF1BVd7UAhBAPE1ENgGPsRSuEEMHdLqZkOGmgCfobTUFb93qBu2asxJXvH4nH3tqAq89owMrtTdjZ1IrLThyOX89cpW3vPZ4qJNozWaze0YS7Z63CWWMH4l+rd+OZRd5SxUC4C8hlAcSYCOZ3c9f6rnt6odWWPSHnjkqQWHjotXW+GSqSlpAsoKpUCrW2C6gqRejIilCrIUmKoWtylWpzy1IUPfYVpxRE8HrrM1IMoGvJ/2gKgIg+CGvA1jpYz+pIIrraHuTFdDHiBoElQZ20TDY3YbXJjbJ4037c/dJq3PvyGmSyAku3HMDLK3YCAJrbTIO6vG4Z1bJoz2TxwtJteGbRFo/g1xWbX+kIte0S2asf0b8em/a2BO734Bx/BSBJygIIM8LUthpjAMo4gKknDsf0d7a61lelyFEANVUpdBQ4cjkOR/ard/3eveuq0J7J+qauXnL8sEjHlb+rej90Ya1+lY/Bh04ajg9POMJzvPs/PxHfenxh7DRnaXEE1QlSt734+KH47OmjYp2jWETtI94B4CIhxBQhxDkALgZwV/GaxRSCX9XMQo8pFYrJBSRH1MqXUnVZuNwTBr+t4wJyZQEJ55g6ussqrByBGk/oyGbRu7YKr958Xt515F3HTmBMBBCvcJ+pN92qTEn4tQ8e7VmfTpNSsqAw0/DqiGWUJXXVKVen4Y5PTsDyWy/FV6eMMW5/92dOMS4HgP49cqUV1NIhkqBOj3xO7vnsRFx8/DCPsrjkhOFY8bNLPftFdQGlfdJA3cciPHDVpMAS1p1J1CehWgixQn4RQqwE4F90nCkpUevmx0EdBmDyHcsUunp7hLB6blcKo/2pxhScILArBpB1atfr6JcVVpBMjSd0ZHITdSdxfwqtKiqJ4xowZdSoI4FN11WlzE5VqAIwVb0MQp1BTW2fX0580L1Qr02YgsAB++q/VfQYQPCG0gKIUsCuqxE1CNxIRL8H8Ij9/XMAGovTJKZQ4mYB5YpR+QvSjBoENmwnU+h61KTR0p5xBeJcKYxKr60qRWjP5Eodq8c9nMk6E5h72qt99xPC2awl7NtdFoCIZbKHkZQCiCM75F2qTpOj/FQLwBT7SadSzjlqIvRUg4h73/TZx2T7/DJigtM43ccF4DIBgrJs9MSC6DGA4PWOAuhqDv4IRFXlXwOwDMA37b9l9jKmC1KccQDBg6lkCl29PeBI7Q2p2TSqsJcvjDMOIOvuqe/3sQBA7lQ/PyEs3Q7tWbdlIfdNopZ/1HLIYcRxAcnbr/bkWw7n7kGoBRAywXkYcQVdJitcnQvZo/brWQf9Luo+jgvIZ72OnlocuYMU8tvI45SjAohqAVQB+I0Q4k7AGR1cW7RWMQUhBV+ytYAEpEoxyVtpAfSssR6plMsC8LqAAJk2l3WOp2cB+ccA7BfdKe1sVgAdGYHqNNDe4bYAwlwQcUgqBpBPxlZNVcqpmqrGWUxySBVOBbuA4loAWeEaByD3zuf+q3uYJhUKaprXAoh4zjALIMHnqbOJ+iTMAqDmodUDmJl8c5gkkKmOScwHIFF9uKYYQFObJaxrq61Hyq+HrlYXlbVTMooFIIVLe9bfAmjPZCPl9suRvOqI3o5MzvKIErQLIykXUD72mirI3QrAbAHI56FQBZCOqa0yugtICsw8mqFeWzZCFpCK97dK5v2Qz1NSs8N1JlEtgDohhFPwXAjRREQ9itSmiuP8O15GOkV48d+nxN63I5PF2B/80/m+7vapuYFgEZ7H19bswsOvrw/d7ifPLEVP270jX+bW9gyO+9HzWnusdWqP83dz33P+FxA4/46XsWZnMwb1ssrgfvOxBXiycSOG9qlDrZ2i+KOnl/j2NJduOeD67jcZSyYr8NF7/4WFG/c5y55fus2pjJlEjy3OwLIg8mmKWn1SbYdRAaRTjiDTS0LExa/omR9+QeDaqvglxQf3rsW2A60AgOH27xhkAYwZ1AsL7Mqx+m/lJ6/1ktJhHancQLDyUwBRn4RmIpoovxDRJADBSdRMZNbsbHZqv8fFVDIhzkjdf76zzfk/bC91PlnAnH8ve9tBBbnW7LSqiahKYu6qXchmBWqVeQbUF/aYob08x9JLHHvbIlzCXxIWhCyEjxjyy6OQT0v8BLnp3qdJLVtc2HXr9+1DJw333TZF1vMoXBaA9XnFqSPws4+egBduzJVv/tOXTvMc49Wbz8XJI/sBAM49bgh+94VJuP/zp+Irk71ppLqw/tlHT8Ctlx9vbJufYH/15nPx9+vPUrYzX9uMfz8Hs26a4ijEcowBRFUANwJ4kojmEtFcAI8DuKForWIiYwpCSsEZZfh90DZ+WUFBQWaTBeB3TH3ofEYI1PkItaF96jzLJo7qb9xWb6eO47Mtwgt76QnRBjHp5BOvMU1BCJgFFhE5wcyCLQDtvo3XSk27t015XEBS8PbvWYPPf2AUjh3W21l32ugBnmOM6N8DE0b0BWApjwvHD8UlJwxT5gPIod/H+po0Lhxv/k38fv7hfesxwVY4gL9yHje0N44e3CvnAupuMQAiej8RDRNCvA3gOABPAGiHNTfwe0H7Mp2DaXLwjCE45keQseC3fy6Tx7uuPYIFINFdCRnNAlAxuQtaQqZt9HPPSF9tMYJ2+frX82mK37n8fNFysd/EJVHRFUDQfaxKW+6UbICbRsXvUE7mkEEcZw3WhUpdtfl6o2ZehQl2eT/iusa6AmFPwgMAZKWtMwB8H8C9APYCeLCI7WIiYrIAsjEsALVHrm/uVzlTvsymHra0APxeGtVlpQsOIfx75aaXOGwidr+6P/K8+QTtwvy8+aZY5iM6fBWA0QKAI10LtQDS2nmDBGQ6Zc10ZrIATPgdSz4XxtWG+IKKX6whqWJw5WwBhAWB00IIOaH7pwA8KIR4CsBTRLSwqC1jIqFnNmSzwun5RrMA/DfyW2cq9yCRaZF+nUw1s0ePX2Sywrd3aHqJwxSAaVYxoLAslKo0BQZ+/dwyYcSt2wTEiwEQckqmM9NAq1KE1vZs5FTNsNHBpn3d4wC86/3uU1LjAKQrs8DbWhLCmpwmIqkkzgfwkrIuagYRU0R0IZwRIpYFkJcLyKnd492gzVEA5pdGVQC6AM8I4duLqjVYAC1hFkCICyhK+V6dMLdRvu6VQrOAQo9FuVpA+WTfqMSJnaQDYgAm/FbJ58K0rzvAbAiA5zHi2N2o4NW5kcDlpwHCWvwYgFeI6O+wsn7mAgARjYU1LzBTYvTeaCYrjDEAIQT+sXiLZ+CS+mK2dWTxnFJF0k+AvrJqJ3YebDP2hGVm0IY9h4z7ygqh6raStTub/F1ABqHVHBIDWLBhr3G5lJv5mOxhwi/vGEBe4wCiCzZSlicdBDZVJ5VUp8kaCBbip3fa6fObBCmNqNaF95jRtgs7plzf7QaCCSH+C8BNAB4CcLbIqdoUrInimRKjC3QhYBxZ+9LyHbjh/xbgty/51+X/xfPL8fVH5+O1Nbs8+6s88MpaXPWHNwMnFPnX6t2hbT//uCGu72t2NvsK2NrqFL51/jjXsq+eY64mKbn5qXeMy9MFuIDCBHw+CuDKSSPyswDiuIAo15GtrdJ9+Pr+weeNZwGQVQtIeUxN7fvmeWMDjyNPacpMu/TEXBrq2XaF10G9alwZWSkCrvrAKO2Y0a4jzD1HBTxPpSbKnMBvCCH+JoRQp4JcKYSYX9ymMVGI6gLa02zF8rfsa3VtH1TYLWgav/d2NQfOmRvG9G+ejV9ecZJnORHh/s+f6nyXvdzaqhT+/cJjcNQAa/zhLz5xIq46oyGvc+de2DxcQCHCryZgWkC/Hvsvr5gQKnR/94VJhuNZ7VdTFgF/AW4asLTu9qlY+/OpmP+jC51lVekU1t0+Fc99c7LxOHFcZ1UpQla4EwpM8vQ/LjoW626f6nsced9NA69PHdUf626finW3T8XYIVZKaeMPL8R9ynO09udTcetHT3DtF1WNhW0n13dHFxDTxTG5gILSNHVM20jBEhRD6FGTLmhKwUG9ao3CNE1uISuFjfRbS3dDIRkXOZ9t/H1Ds4ACDhrkew8vOexdJmMA1VqbTMci5EwAU/ZTWP2gKMuDti10xLQzF0WCU0tGLpUS8XK7pQXAdG3adZ++knNtqsCoY3qh9CqdJnrUVBX0Uvetr/YN2KkvksytlmmgskkFKYACineF1Q8K8q/75aMD4fPzmn4/qWz0/HO/NFC53DhQzNDP9ZPznhhAQNNlG03jVeIQ5ALKl+gxgDAXULTtuiKsALoQ+Tzc7ZrgUGuvB02I7WxvEDzyBfcbBwBYIyxNE7dHpa46bexJpohcL5LcxrEApAIo4MnNlYKIf5Aw90fQ+iALIExAmoSLVDa61eEniKSQNwl7Ug9h32O/TkOcInqOBaA8K/kEvNOOBRB7V1+SE9jSomQFwBRAPrXldQtATbnLtxSEfPGDdu9Zky4oBgCYe+BWT1V1AeViACqFvLyFjAMIjQF4hHHuf1MqqyTMmjLdK8cC0Efm+rh45CFMt84105bjZjO3pTpmDABAwc9KKkKnJC6RYwAhG8r13bkYHNMJ5POS6Ptks7lekipT/JSBSe5EUSD1BcYAAPOL1dqeNcYA6qqlBZBcDKAYI4F1F5A6faIplVUSdi9Np5VBZd0C8HPx5FwVpvWmc3adGEDKsQCSUwDRZwQLcQHJ7VgBMHFRXTPtHeEP97V/asRT8zYBAL74P2/h2cVbXesff3sDnl20BYD1svzPv97DzX9ZjNZ2S1Hsbm7DJb+eg/W7m7Fp7yHMWLbdc47P/f5NHGxtDxRKb6zdgxeWbvNdHwWTi6GprcPHBWTHAOzlSVgA+fTYwoSf7o9XA7SFWACmeyUFThQXUHUVoVdtlXF7fZ+wOIt+jUEtlwpw/W7zuJCo5GIABR3GTcSfPzQLyN6g240DYIqP+t77lS5QeXHZdtz05CJksgKzV+zEdE0B/HpmLs9fCOCnzy7DE40b0WbPGfvyip1Yvu0gHpizFg+/ts73PI3r9jovW58686DvR97YENpeEz+c+j7fdc1tHS4h64xerXZnJsVx31w35WicPXaQ810KQFXAPfW1M/ErQ1pqUKljE7pSUYvbSQFsIswCSKcIz95wtnuZVGSeILD7+4SR/fDhk47Azz9+Em68YJzrXkjMFUTNbRk7uBf+7cwGXHHqCNz/+YmudXqJ7qTcIvKaCrU63ceMtl3UbCGOATCxUV04cWaXijIVoWuUb7us0ml9b2rtCH6wKfeyfU4bQFMoF44f6ruuqbXDJdxlE3MuILk8+GVTBxZ9ZMIRmHLMYOe7VCbyhb1y0gicOqo/PjlppDPOQPJlreZ8WPkJvV31igLoW1/tu1+YBZAi4ES7JLKzzKekhS6Hvn3RMahKpzCgZw1uvOAYo6BSmy0My1Rqq1O45SPH478/OQGXnJBTkNeeM8bz2yYlFOW1FiMNNNTHH3YcDgIz+aJPhB4V2aMPQn1XZI0eKUibDZO5qKSInJet0OJhpmP7cbDNrJjiuoD696xx/u/bo9olYGWgVt77ngE9c92sN02CE0SPmogKIET5m+6J34hmfVv9XpnundsFFFxM0D/LyEtSPfZiuICctNiQ7aIGgVkBMLFRM39Ms3upqPEC6dMPIuva3lIY8hFtausITDsl5NxTegZOoYS9KGmXMJJtcFsAYTpJFbx96qqQUSwtKcCa26x7EuSa0dsaVoFUp15tRwEWgHHQXMSaRvp6v/TbqOibBgnluPfLj2K4gKKmo4aXgrA+y3EcQEkrehLROgAHAWQAdAghvOPduzlxLAB127gWQIutAORnWCE1opwCKXQCEZ0wv7AqoIRHCQm7fdGFXq/aKlcJAXl+OZF9HAUQdt90VBdQnzp/BZBPFpB0i4TdC71Ym1+xOM9+MS0AE4di3i8/5PUn6wKSn4UJ7nzGNXQVukJJ53OFELtK3YhSEScG0OFSAPEsgIOyvo+9qLktE1yWFzkXUKHVI3XC0uVUAaO3wbEAQl5aNTBKRC4LQK5rsi2AQBeQdulx5Y9qiQRZUuExgOguIB1Z28nZL2IMIE5b/JBWVqHkSkEkcjj7mPZnwQeyPpJMUOos2AWUMK3tGWw/0Bq+oY3a85MKYHdTGw60tgduu3Zn+CTyqgJ4e90e17rNe1uw79BhfRcHolwxuKRjAGHCW41ptmtzDEeNAejr1QFE0gKQcZBgC8D/2qNkuKguoCDyGQkcdSYqPW5hLhXhtbr8yjz7XrZhedyYiR9OeZIiuIAK9dyUb/+/9ApAAHiRiOYR0bWmDYjoWiJqJKLGnTt3mjbpUlzz8Ns4/bZZkbdX3T5S2J36s5k48+cvebdVHv7rHgkvxqq+K1v3u5XS4UwWf27cFLCvUILAyT7iQaUEjh7c06UgLhxvlYyWQjo3EMxaf8KR5gnJ0yly9b5PPLKvss567Cce1Q8AXJOSe46jSYfxw3PnixIbqfOZ41gyZlBPABEsAMOpnElSQtowaqA7synMArvsRKuMsgxaN2j7B1mOp9j3VDJpVH/PNoN613iWhVEMF5BUKmomUyEkWaeosyi1C+hsIcRmIhoCYAYRLRdCzFE3EEI8CHv+4UmTJnX5Oyzr4AshIvkW1V69+r+p5xQ3AFbIzepQqoom7QIyWQD/mnYe6qvTqKtOuZTVf15+Am684BjHTeNYAPbL++RXz8Tu5jac/YvZruPVVaXx5vfPd+7ZJScMx1UfGIX/fWO9o9CuPrMBF4wfihH93QJORRW8f/36mchkBT55/+vWOarTaA4JcqpKggiY/6MLMfHWGQCs/2WBuNBxANo9+78vn46V2w8CcP/Oi358kWu7V28+13N9fhbYWz84H4c7shjSuw4A0K9HDd743vlYtnU/vvRQY2D7JJeffCQmNQzAWbdbHZh/O6sB//nRE1BfnUZNVQoHW9sxvG99yFG8FMMFlE4R3vr++ejXI75CUik0hlBKSqoAhBCb7c8dRPQ3AKcBmBO8V3nQnhGBteElHT4KwLxtvFIReo9kQM8aZ16AMDKZXFXRpIPAJh+0OoBIFVDV6RSG9qlzvuujVOtr0hhR4xXgtdUp9NaCrsP61rnOT0SBwh9w59gP71uHHQfacueIoBh14TBASU9V/487EnhQ71qs2mG5AdWfuW8P9zWbrs8vC0sKfpVhfescReOH7ipSf8sUket7kLstiFwxuGT7gEP6eK85LuUr/kvoAiKinkTUW/4P4CIAS0rVnqRpjZClA7iFelihq7jVN3WFEufl68hmnf07cxxA2HrdBeSHqfKmjLHEyddWLQCCu1JpbYh7B4g+2jQ8BqB/z9X2CZqS0UTcDmvU7Y1VRhOSjvJ3SFoBJEkXbpovpbQAhgL4m92zqQLwf0KI50vYnkRpa88CEToXqlAPC3DFdQHpo4WDsl087coKR9gm7QIKC54GFZvMlYMOPoapdy7vX6xiZooEUytqAtFiI1EzZqKUglCpSuXEbVzBE3fAUiFpjkmlSKaK4AJKimLEJzqLkikAIcRaABNKdf5ikU4RMlkRKU8f8I8BmIhbUVHm/Et6x1AAmaxwCUx5XUkQJryDBFTULCBT8DUfi6bKbQK4FEAU4RZVAcRNA00r2ijurxK3aFkhvfikBscWoxpoUpRzDKDUWUDdDim8oozUBdwvfpgQyMSMAeh1a3r5FHUztkuJAaSIOnWYe5CAklZJmBAzWQAdeVgAqoxPEcXu0UZWAGEuIK3NqRTlXR4hbtnisK2Dzp+UcHQUQFc0AWy6oG4KhRVAwsiAaeO6PXj0zfWYt34vnng7VzWzrSODH/ztHTzZuBGAu9ev925eW7MLOw604s4XV2DT3kO4c8bKWG3RLYA4MYCbnlyEW55ZCsDuxXXiwx0kNMIKlUlMpZeluy1WhUrlugnxZyJLuw0IX6IUg1OxXEC2BRBT8hSrZIHpsMlZANZnl7QA7M+u17JwSp0G2u2Qo0yn/fUd1/JPvf8oAMCq7U149M0NePTNDfjkpJHuILDidweAz/7uTUw5ZjBeWbkT98xeHdv/qY8WjhMDAIAVdvZHKkXoWZvG4UPW8T79/pF4/G1LgX3opOG46PhhmLFsuzMPgYnvXHwsfvXCCs/yL5892pXlA4S4gLQsID9Mk69cM3k0GtfvwcdOOTJwXwD4/mXHYc7KXeitWE36dJW3ffwEfOI+KyX0Jx8ej3W7ml3HuP7co/HZ00fhyXmbUFuVwocnHOF7vjuvPBlXPvC673pTQTfK0wKIXbc+ZPNPThqB6Yu34ipD1dikdM3Z4wZhwoi++PZFxyZzwAT5xvnjsGpHEy58n3+V264KK4CECetd6uUe9BiA3hOURdzUxZ+aNBJP2BZEELrPvrfBBTR53CDMXRVciSNFhJsuOhY/fHoJzjx6IG7/xEm4/RPu2vkfmXBEoAK4/tyxRgXwww+N9ywLdAEhmhvHZAEc2a8ez2g19f2YPG4wrj3naNcyopwsHNqnFqeOGuCs++JZoz3H+M7FxwEAFmq5+SZOGz3As+zBq07Ftf87D4A5BpDreca0AGJaMWFuryG96/Dctyab901IA/Suq8bfI/52nc3oQT3x7De6ZtvCYBdQwoRNGq4LeDULKJMVnlRPk6ALmlkqCJMLqD5iKqP0qUeZh6BQImUBhciVQscuGAumEeVqyHdC9rcarNavN50qwALoxHhO+YZHKwNWAAmjz84kkcErfRJ310AwITwloY0KIM+0TJMC6BGhVk2KyMl5jzNpTb5EyQIK61lWFawAvMuIkvNpm9AvSX2WzBZAfllAcWMAhWUBsQroyrACSBi/FEMp2Ns1CyCjxQD0bBD5Aqk92rD6Mn6YsoCi5PinU4Q6aQHEHIyWD4FCQ1YDLXIv1jgHr2oBFOH0+iFdFoB2vWnFHxU7CyiuAoh3ePe+LP+7NKwAEsYvBiB9+YEWQFa4JogBcj1OtTeYrwVgGgcQVO1SQpQb9Xo44viGQggcCYxoI4ELb4N3GSnLi3F6/bqrXRaAe9t0KheQjpsFFHsgWAFSnC2Arg0rgITxcz3IjBy9no+eBqq7WJwyyMo7bipzEAWTBRDFU5IicpSOrqCKQZCAykbMAioUv2kTi3lerwJI+a5Tg8BxUyPLcOZCpkhUrALYsPsQGqZNx0vLtyd6XL/e+em3zcL0xVtdLpTJv3zJFfTtyHgVwMx3dwBw5/TX5RkENqWBRkkJTKfIcTt1RgwgSEA5tYCK7gIKXlaU0Z+eXP/c76wrRbUsRVyVHLftHAPovlRsGujCTfsAAE/N34zzjksufzfIPfPnxo24/ORcLvjGPS0eCyBKuYd8LQCZ8VOVIkwc1R9vvbfHIwyeveFsfPieV13L4mYBzf3uudjTfBjbD7SiYVDP2JlDUQaC+cn/l26aktgsVDqmZslrVZl105S8sqX0a1KryernpgLGAeTbrqF9avHAVfFmbc23+ifTOVTsr+O8bAm/PEHmeG1VytODbteCwFEER75poFKIV6UJF40firfe2+PpWZ44oq9nP8sFZG0XNnE9AIwc0AMjBwSXWc6XsCkhGwb2LJp1oPZm5b+maz16cK+Cjw9oFoCPSwrojBGo1nmO6FePk0f2i7WnnFSG6ZpUsAKwHuqkh5YH9eDrqtMeH7rLBWQYCGYi3yCwdOOkKTffb5SAYIoI1fY545akLhZ+VkIxPQ6E4va2PTGAKv8YgEpnzUSVz2ni1J9iOp+KjQHkG0ALI6hYlckCUGf+yma9MQDjcfJMA5WKI5UiyNNE8dGmKJcG2hkxgCj46a1iVmZMETlZSEUJAWjHrE75u4Bke4DiWwD5xhqAzh10xsSnchVAkeqLB03qUlud8vSgVf9xxpAFZDxOnhZArRIDyFkA4edJpXL7xi1JXSxKIVjiloKOS1AWkEmx5WIAxf1NWIR3XypWAaSK9PIEuUiqUimPD92lAAzjAEzkGwSWAl2t7R+UBSSnVCQlDbSrUIoa7ERUVBdQ0Ehg4/ZONdBitUijC1biZAqjYhx0Ly3fjtNGD3SyEsJmGFq6ZT9qq9IYO8Qd0Nvf0o6nF2zGeccNcQX/Zizbbh/P/yX5x+Kt6FvvvuW6Anj7vT2h15Jv77c6nXIGEGUjpFP2rqvCrqY2tLZnEp8WslBK5VmIWo46H4IsABOdlQVEnRZsZjqbrvVWF4n1u5vxpYca8d2/LHKWyQQLPwtg6t2v4oI7X/Esf2bRFvzkmaW4S6nNn80KfOVPjfjKnxqRyQrf8gq7mtqwZqe7ZLBUADXpFDJC4J9LtoZez4AeNaHbqEweNwiDeln71FalUJUinHfcEADA+UoK7JlHDwRgCf5LTxiGr02xqmEO6lXrbPPVc8b4nucTE0cEtuOkEX0xbkj0DJlPTRrpu65YLqCvTB4NwH3N15+bqwo6pLe1/Mtnj877HH3rq3HB+4Z4ln/9g9Z5vnHeWACWApDtkaj3+CQ7Y+uKU0fgtIYBGDkgN/n62CG9MMGQ0aVyxanBv5ekYaDV0TGVew7a54wxAyNv3xW55PhhkYolljPUWRkESTBp0iTR2NgYe7+lW/Zj6t2v4rhhvfH8jecAAGYv34EvPvQ2phwzGA9/6TTPPg3TpgMA1t0+1bX8t7NW4Y4ZK3HR+KF48AtWTnTL4Qze92NrOuORA+rR1NqBvYfanX2evO4MfPJ+c633I/vVY+v+FtRVp/G504/CzHd34D2trnxVirD6tsuc73ubD+OUW2dEvv41t13mCMxT/vNF9Kytwqs3nxd6rV0R2dblt17iqolUTtfAMJ0NEc0TQngGcVSEBWAi38yG/S2WYD+kTLeozv/b1p5Fjxq3myeoF7G7uQ1VqRTSROjwGQegB17TESYjd22v9JbrqtPdIjODR5gyTOFUhAIwTaXr+DUNFlDQ/KxSAchPwD3z1uFM1lNiOajiZmt7FlVpQipFyEacTD7WlIYatVWpbqIASt0Chil/KiIIbBKqMghqCtoebO3wLJMcaG13fQK5Sp+AVSpBVwBhAjudIlSlCBkhIk0mX4gAr61Kd8l5VePCFgDDFE5FWAD63LhArudvsg7U3r3fOj8LoK0j6xmoFZbNUZUie3BWVAsg/5+ttrqbWADd4BoYptRUiAIwWAC2zDb1htXevWddS4f92e4okbZ2dz0ffTrCMAWQtmMA7Zlo4wAKEeB1VWnuPTMMA6BSXECKgP5z40bc9/IaJ9hq8oaovfsH56zBlGOG4Ir7XkPT4Q5n+6wARn/vOUweNwjXnzvWtb9errk6JGhblSJsO9CKv8zbFOey8qK2OoXWjvJVAEQ8HolhkqIiFECrYgHMWbnTlWYpDHlAspcPALc9txxzV+3CQaVmzw8uex9+9eIKHO7IYu6qXfj4xCNd+x/Rrx7fufhY/OqFFQCsSWL+/NUz8NS8TRAQ2N10GLOW73C2D+rRv7+hP757yXGe5T/9yPE4fcwAvLpqFz547BDMenc7fv7P5UG3AQDw5clj0HLYP8bR1Xn+W+fgjbW7S90MhukWVIQCUC0APR5gGgkcFAMAgC+e1YBhfevwjccWAAB2N7nrwTe3ZXD9uWMdBVCTTuG00QNw2ugBAIC/zt/kUgBBQ/6vnDQS728Y4Fl+9ZkNAIDjhvUBYA38iaIAphwzOHSbrsyxw3rj2GG9S90MhukWVEgMIEgBeDVAmAKoSqfQR6lzvuNgm2t9U5t7f90FpJ8yKEuo0BIMejyCYRhGUhHSQU3TbGt3B4RNFoAeBDYVHlMnuthxoNW1Tp+RSnfx6EpHz+pRxw0UGq+tr+neQ9kZhsmfkioAIrqEiFYQ0Woimlas86i9/lbNAjANBNMtANM2fQMtALePXVcg+tF0BaFaBIVWvdTHJDAMw0hKpgCIKA3gXgCXAhgP4DNENL4Y55JpoB1Zgbb2jMslY8ooOaApAF2gA0AfZaajnSEKQEdXKHoMQC0Hka/4lzqELQCGYfwoZRD4NACrhRBrAYCIHgdwOYBlSZ9IBoFX72jCUQN6YEjvOmze1wIA2LDnEDbuOYT9Le2O4N6w55Br/w273d8BuGIAq3Y0udY1hyoA93c9L1+t/ZOvASAPwRYAwzB+lFIBHAlgo/J9E4DTi3EiNQ10w55DmDCir6MA9re0Y/IvZwfuv1up2X/04J4AgoOzk8cNAgCMH94Hy7Ye8KyXcwwcNaCHR9kAVoVQ2b58ufSEYfjnkm04Tyn3HES5jw0b0b8em/YWds8YptLo8mmgRHQtgGsB4KijjsrrGNecPQaTRg3AjU8sBJCb6Urn1o+egCfe3oAlm3NC+5xjBuO6KWMwvG89CMDg3rk68W9+/3yc8fNZyApgzKCeWGuPL/jZR08EAPzla2cY3UGTGgZgznfOxQtLt+G/nnsXNVUpLPzxhSAi7Dt0GHfOWInNCy1hls/Ug8/ecDbeN7w3tu5vxZH96kO3X/CjC8u+tMILN56DlvbwMhoMw+QopQLYDECd8WOEvcyFEOJBAA8C1nwA+Zxo9KCeGNonJ7h71prdImcdPRCzl+8AkFMApzX0x5lHDzJuP7RPHeqq0zh0OIOJo/o7CkBm8fSoqfKUhpYcNbCHM2K4rjqNfvYkL33rq10uonx65qMG9UBVOuWasSyI/j3jTTDTFelZW4WetV2+P8MwXYpSZgG9DWAcEY0mohoAnwbwTLFOpubD9/QRyn3qqz1z31aFTctnfw7MQ4jKuX31c6paLp9+Oef+MwwThZJ1mYQQHUR0A4AXAKQB/FEIsbRY56tKp5AiKzjaw8cC6FPnVQBBk6arDMhDAUhLIWjC9XwsgELmC2AYpnIoqc0shHgOwHOddT6yK4n5WQA1VSnXNIPWPtGOnY8bRaZ7SktA4k4TjS/Mu0O5Z4Zhik9F+QqkYA3yFeu98agDsfJxAcnxCbXV/i6gfCh08BjDMJVBRSkASVBufForyxBVlMogbhzk7F9Ju4AYhmGiUFEKQA6O6mNIA71uytEAvAI3TADff9WpmDxuEAb1iq8APnrKkTjhyD645uzRruU3nj8ORNZ4gDOPHhj5eHdeOQEXjY+W988wDFOReXMDFWG9/NZLXH5/Xd6HzZ41edxgTB43GFvyGLg1uHct/vGNyZ7l44b2xns/nxr7eB+fOAIfnzgi9n4Mw1QmFWUBSFR3jS7gdf97VBcMZ94wDFNuVKQCUCt5hsntqAFVzrxhGKbcqEgF0Kc+5/nSBbcuxqOKdVnTn/UAwzDlQmUqACUIHFarPywGIEnbJZ05BZNhmHKhIhWAPtgriLgxABb/DMOUCxWpAIIY3rcOADBqoFVILWqJB+lKOmYoT1jOMEx5UFFpoHO/e65n+kadL541GsP61uGi8cMwY9n2yHn11ekU/vSl03DCkX2TaCrDMEzRqSgFMHJAj9ASyekU4UMnHQEAmHrS8FjHP+eYwXm3jWEYprNhFxDDMEyFwgqAYRimQmEFwDAMU6GwAmAYhqlQWAEwDMNUKKwAGIZhKhRWAAzDMBUKKwCGYZgKhRUAwzBMhcIKgGEYpkJhBcAwDFOhsAJgGIapUFgBMAzDVCgVVQ1U5dEvn46dIaWhGYZhujMVqwDOGjuo1E1gGIYpKewCYhiGqVBYATAMw1QoJVEARHQLEW0mooX232WlaAfDMEwlU8oYwF1CiP8u4fkZhmEqGnYBMQzDVCilVAA3ENFiIvojEfUvYTsYhmEqkqIpACKaSURLDH+XA7gPwNEATgawFcAdAce5logaiahx586dxWouwzBMxUFCiNI2gKgBwD+EECeEbTtp0iTR2NhY/EYxDMN0I4honhBikr68JEFgIhouhNhqf/0YgCVR9ps3b94uIlqf52kHAdiV575dhe5wDUD3uA6+hq4BX0M0RpkWlsQCIKL/heX+EQDWAfiqohCKdc5GkwYsJ7rDNQDd4zr4GroGfA2FURILQAhxVSnOyzAMw+TgNFCGYZgKpZIUwIOlbkACdIdrALrHdfA1dA34Ggqg5FlADMMwTGmoJAuAYRiGUWAFwDAMU6FUhAIgokuIaAURrSaiaaVujx92WYwdRLREWTaAiGYQ0Sr7s7+9nIjobvuaFhPRxNK1PAcRjSSi2US0jIiWEtG37OVlcx1EVEdEbxHRIvsafmovH01Eb9ptfYKIauzltfb31fb6hpJegAIRpYloARH9w/5eVtdAROuI6B27anCjvaxsniUJEfUjor8Q0XIiepeIzugK19HtFQARpQHcC+BSAOMBfIaIxpe2Vb48BOASbdk0ALOEEOMAzLK/A9b1jLP/roVVXqMr0AHgJiHEeAAfAHC9fb/L6TraAJwnhJgAa7zKJUT0AQC/gFXFdiyAvQCusbe/BsBee/ld9nZdhW8BeFf5Xo7XcK4Q4mQlV76cniXJbwA8L4Q4DsAEWL9J6a9DCNGt/wCcAeAF5fv3AHyv1O0KaG8DgCXK9xUAhtv/Dwewwv7/AQCfMW3Xlf4A/B3AheV6HQB6AJgP4HRYozWr9OcKwAsAzrD/r7K3oy7Q9hGwBMt5AP4BgMrwGtYBGKQtK6tnCUBfAO/p97MrXEe3twAAHAlgo/J9k72sXBgqcqOktwEYav/f5a/LdiOcAuBNlNl12K6ThQB2AJgBYA2AfUKIDnsTtZ3ONdjr9wMY2KkNNvNrAN8FkLW/D0T5XYMA8CIRzSOia+1lZfUsARgNYCeA/7Hdcb8nop7oAtdRCQqg2yCs7kBZ5O0SUS8ATwG4UQhxQF1XDtchhMgIIU6G1Ys+DcBxpW1RPIjoQwB2CCHmlbotBXK2EGIiLLfI9UR0jrqyHJ4lWBbVRAD3CSFOAdCMnLsHQOmuoxIUwGYAI5XvI+xl5cJ2IhoOWEX0YPVIgS58XURUDUv4PyqE+Ku9uOyuAwCEEPsAzIblLulHRLJ8itpO5xrs9X0B7O7clno4C8BHiGgdgMdhuYF+g/K6BgghNtufOwD8DZYyLrdnaROATUKIN+3vf4GlEEp+HZWgAN4GMM7OfqgB8GkAz5S4TXF4BsDV9v9Xw/Kpy+VfsDMGPgBgvyhyQb0oEBEB+AOAd4UQdyqryuY6iGgwEfWz/6+HFcN4F5YiuMLeTL8GeW1XAHjJ7tGVDCHE94QQI4QQDbCe+ZeEEJ9DGV0DEfUkot7yfwAXwaocXDbPEgAIIbYB2EhEx9qLzgewDF3hOkodIOmkIMxlAFbC8uP+oNTtCWjnY7AmyGmH1Wu4BpYfdhaAVQBmAhhgb0uwspvWAHgHwKRSt99u19mwTNnFABbaf5eV03UAOAnAAvsalgD4sb18DIC3AKwG8CSAWnt5nf19tb1+TKmvQbueD8Kac6OsrsFu6yL7b6l8d8vpWVKu5WQAjfYz9TSA/l3hOrgUBMMwTIVSCS4ghmEYxgArAIZhmAqFFQDDMEyFwgqAYRimQmEFwDAMU6GwAmAqAiLK2BUl5V9gVVgiuo6IvpDAedcR0aA89ruYiH5qV4z8Z6HtYBgTJZkUnmFKQIuwSjtEQghxfxHbEoXJsAZtTQbwaonbwnRT2AJgKhq7h/5Lu+b8W0Q01l5+CxF92/7/m2TNb7CYiB63lw0goqftZW8Q0Un28oFE9CJZ8wj8HtagHnmuz9vnWEhED9ilyvX2fMouQvdNWMXcfgfgi0RUTqPXmTKBFQBTKdRrLqBPKev2CyFOBHAPLKGrMw3AKUKIkwBcZy/7KYAF9rLvA/iTvfwnAF4VQhwPq3bNUQBARO8D8CkAZ9mWSAbA5/QTCSGegFVBdYndpnfsc38k/0tnGDPsAmIqhSAX0GPK512G9YsBPEpET8Maxg9YJS8+AQBCiJfsnn8fAOcA+Li9fDoR7bW3Px/AqQDetsoloR654l86xwBYa//fUwhxMOziGCYfWAEwjLsMr6k2ylRYgv3DAH5ARCfmcQ4C8LAQ4nuBG1nTHg4CUEVEywAMt11C3xBCzM3jvAzjC7uAGMZyzcjP19UVRJQCMFIIMRvAzbDKJPcCMBe2C4eIPghgl7DmPZgD4LP28kthFf0CrKJfVxDREHvdACIapTdEWNMeTgdwOYBfwiqAdjILf6YYsAXAVAr1dk9a8rwQQqaC9ieixbDmAv6Mtl8awCNE1BdWL/5uIcQ+IroFwB/t/Q4hV9b3pwAeI6KlAF4DsAEAhBDLiOiHsGa3SsGq+Ho9gPWGtk6EFQT+OoA7DesZJhG4GihT0dgTpkwSQuwqdVsYprNhFxDDMEyFwhYAwzBMhcIWAMMwTIXCCoBhGKZCYQXAMAxTobACYBiGqVBYATAMw1Qo/x8X9muUcIt0KgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instance of an agent to interact with the environment\n",
    "agent = Agent(state_size=37, action_size=4, hidden_layers=[18,9], p=0, seed=0)\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=250, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        score = 0\n",
    "        while True:\n",
    "            state = env_info.vector_observations[0]  # get the current state\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)  # this statement launches the learning phase\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent():\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    score = 0\n",
    "    while True:\n",
    "        state = env_info.vector_observations[0]  # get the current state\n",
    "        action = agent.act(state)\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        state = env_info.vector_observations[0]        # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        score += reward\n",
    "        if done:\n",
    "            return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    run_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hundred_runs = [run_agent() for i in range(1)]\n",
    "hundred_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-37d3a428681a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# get the current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, train_mode, config, lesson)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_reset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             )\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "score = 0\n",
    "while True:\n",
    "    state = env_info.vector_observations[0]  # get the current state\n",
    "    action = agent.act(state)\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    state = env_info.vector_observations[0]        # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward\n",
    "    if done:\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'state_size': 37,\n",
    "              'action_size': 4,\n",
    "              'hidden_layers':[18,9], \n",
    "              'p':0, \n",
    "              'seed':0,\n",
    "              'state_dict': agent.qnetwork_target.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_size': 37,\n",
       " 'action_size': 4,\n",
       " 'hidden_layers': [18, 9],\n",
       " 'p': 0,\n",
       " 'seed': 0,\n",
       " 'state_dict': OrderedDict([('hl.0.weight',\n",
       "               tensor([[-0.0042,  0.0019, -0.0332, -0.0384,  0.0440, -0.0412,  0.0340,\n",
       "                         0.1042,  0.1362,  0.1232,  0.1886, -0.6663, -0.2183, -0.1953,\n",
       "                        -1.2479,  0.0197,  0.0420,  0.0463,  0.0370,  0.0001,  0.2111,\n",
       "                         0.1635, -0.0764, -0.2658, -1.2271, -0.0547, -0.0379,  0.0607,\n",
       "                         0.0611,  0.0589, -0.3189,  0.1211,  0.1263,  0.2343,  0.2072,\n",
       "                        -0.0075,  0.0004],\n",
       "                       [ 0.1087,  0.1781,  0.1242, -0.0005, -0.1190,  0.0776, -0.1473,\n",
       "                        -0.1631, -0.4078, -0.7985, -0.0570, -0.0017,  0.0653,  0.1002,\n",
       "                         0.0807,  0.1429,  0.0534, -0.1207, -0.1960, -0.5320, -0.1982,\n",
       "                        -0.0146, -0.0519, -0.0125,  0.1884,  0.0870, -0.1503, -0.0180,\n",
       "                        -0.3431, -0.9447,  0.0681,  0.2498,  0.0063, -0.0635, -0.1287,\n",
       "                         0.0154,  0.0073],\n",
       "                       [ 0.1362,  0.1338,  0.1756,  0.2083,  0.0503,  0.0543,  0.1146,\n",
       "                         0.0397,  0.0622, -0.0673,  0.0227,  0.0479,  0.0419, -0.0283,\n",
       "                        -0.0237,  0.0369,  0.0903,  0.0941,  0.1512,  0.1546, -0.7487,\n",
       "                         0.3543,  0.1535, -0.2536, -0.8662, -0.0412,  0.1909,  0.1278,\n",
       "                         0.0037, -0.1120, -0.0099,  0.0206, -0.0514, -0.1307, -0.1596,\n",
       "                        -0.0269,  0.0056],\n",
       "                       [ 0.1570, -0.1118, -0.0338,  0.0110,  0.2466, -0.0984, -0.0619,\n",
       "                        -0.0067, -0.0001,  0.1564, -0.0996,  0.0606, -0.0827, -0.1569,\n",
       "                        -0.1557, -0.1456, -0.1510, -0.1117, -0.1085,  0.1378, -0.2434,\n",
       "                         0.0745, -0.0038, -0.0509, -0.1083,  0.0609, -0.3455, -0.1311,\n",
       "                         0.1542,  0.5758, -0.0434, -0.0559, -0.0305,  0.0199,  0.1591,\n",
       "                         0.0054, -0.0001],\n",
       "                       [-0.1334, -0.1667, -0.1415, -0.0166,  0.2498,  0.2699, -0.6279,\n",
       "                        -0.0243,  0.0300, -1.5544, -0.0223, -0.0044, -0.1032, -0.0925,\n",
       "                         0.0201, -0.1981,  0.0132, -0.0382,  0.0684,  0.2045, -0.0930,\n",
       "                        -0.0172,  0.0982,  0.1174,  0.1686,  0.2175,  0.1227, -0.2647,\n",
       "                        -0.2960, -1.2974, -0.0568,  0.3292,  0.1140,  0.0274,  0.0166,\n",
       "                        -0.0375,  0.0051],\n",
       "                       [ 0.0200,  0.0205,  0.0163, -0.0129, -0.0361, -0.0018,  0.0057,\n",
       "                         0.0902,  0.1309,  0.1002, -0.0372, -0.0445, -0.0314, -0.0280,\n",
       "                         0.0436,  0.3267, -0.6277, -0.5058, -0.4624, -2.1059,  0.0733,\n",
       "                         0.1123,  0.1140,  0.1102,  0.0300, -0.0526,  0.0650,  0.0870,\n",
       "                         0.1207,  0.1306, -0.0825,  0.0443,  0.0358,  0.0034,  0.0466,\n",
       "                         0.0139,  0.0008],\n",
       "                       [ 0.0018,  0.0261,  0.0747,  0.1819,  0.1925, -0.2016,  0.1060,\n",
       "                         0.0861,  0.1966,  0.3732,  0.1320,  0.1692,  0.1017,  0.0324,\n",
       "                        -0.0595,  0.0339, -0.0315,  0.0756,  0.0873,  0.2174, -0.0069,\n",
       "                         0.2239,  0.0767, -0.1382, -0.4366, -0.1846,  0.1017,  0.0872,\n",
       "                        -0.0092,  0.1415,  0.1768, -0.0059, -0.0846, -0.0051, -0.2954,\n",
       "                        -0.1165, -0.0075],\n",
       "                       [ 0.1093, -0.0259,  0.0533,  0.0956,  0.0831,  0.2241, -0.0947,\n",
       "                         0.0490,  0.0256, -0.0940,  0.1561, -0.1614, -0.0159,  0.0838,\n",
       "                        -0.0233, -0.2581,  0.0980,  0.1331,  0.2367,  0.4677,  0.1003,\n",
       "                         0.0601, -0.0343, -0.0529, -0.0813,  0.0511,  0.0947,  0.1550,\n",
       "                         0.1452,  0.2304,  0.1415,  0.0359,  0.0404, -0.0024, -0.0972,\n",
       "                        -0.0733, -0.0244],\n",
       "                       [ 0.3507,  0.1139,  0.2210,  0.1279, -0.0740,  0.2498,  0.2288,\n",
       "                         0.1964,  0.0856, -0.0684,  0.3337,  0.2308,  0.2419,  0.0959,\n",
       "                        -0.0341,  0.3198,  0.1570,  0.1344,  0.1689,  0.0236,  0.2235,\n",
       "                         0.1959,  0.2234,  0.0931, -0.1615,  0.3180,  0.1243,  0.1185,\n",
       "                         0.1959,  0.0868,  0.3526,  0.2145,  0.2437,  0.0576, -0.2082,\n",
       "                        -0.0535,  0.0555],\n",
       "                       [ 0.0375, -0.0791, -0.0129,  0.0338,  0.1072, -0.2139,  0.0844,\n",
       "                         0.1330,  0.2626,  0.4215,  0.0018, -0.0761,  0.0638,  0.0521,\n",
       "                         0.0275, -0.0746, -0.0417, -0.0134, -0.1077,  0.0926,  0.0302,\n",
       "                        -0.1653, -0.0774,  0.2198,  0.4772, -0.2324, -0.1614, -0.0714,\n",
       "                        -0.0163,  0.1409,  0.0115,  0.0682,  0.1276,  0.0794,  0.2811,\n",
       "                        -0.0200, -0.0396],\n",
       "                       [-0.0952, -0.0520, -0.0513, -0.0211,  0.0714,  0.0486,  0.1178,\n",
       "                         0.0891,  0.0948,  0.0951,  0.0322,  0.0772,  0.0673,  0.0563,\n",
       "                        -0.0455,  0.0757,  0.1164,  0.1131,  0.1353,  0.0354, -0.0938,\n",
       "                        -0.0630, -0.0553,  0.0034,  0.0976,  0.4884, -0.4510, -0.3507,\n",
       "                        -0.3454, -2.0181, -0.0226, -0.0013,  0.0195,  0.0602,  0.0906,\n",
       "                        -0.0176,  0.0084],\n",
       "                       [-0.1242,  0.0791,  0.1074, -0.2330, -0.4691, -0.7412, -0.0621,\n",
       "                         0.2649, -0.6364, -1.7746,  0.0609, -0.0933,  0.0028, -0.1028,\n",
       "                        -0.2316, -0.3652, -0.0411,  0.1537, -0.3787, -0.5325, -0.0710,\n",
       "                        -0.1368, -0.0084, -0.4251, -0.1245, -0.4180, -0.2297,  0.1665,\n",
       "                        -0.7507, -1.2743, -0.3673, -0.0759, -0.1182, -0.2664, -0.5203,\n",
       "                         0.1511,  0.0888],\n",
       "                       [ 0.1589,  0.1697,  0.0360,  0.0642, -0.0603,  0.0428,  0.2684,\n",
       "                         0.2091,  0.3220,  0.0778, -0.0418,  0.3105,  0.1566,  0.1954,\n",
       "                         0.0086,  0.1212,  0.0204,  0.0581,  0.0665, -0.1456,  0.0476,\n",
       "                         0.2578,  0.1966,  0.2009, -0.0461,  0.1176,  0.2047,  0.2122,\n",
       "                         0.2303,  0.0059, -0.0671,  0.1074,  0.0546,  0.2164,  0.1598,\n",
       "                         0.1053, -0.0031],\n",
       "                       [-0.0583, -0.0079, -0.0248, -0.0034,  0.0162,  0.5246, -0.6473,\n",
       "                        -0.5424, -0.5455, -2.0057,  0.0276,  0.0519,  0.0597,  0.0774,\n",
       "                         0.0207,  0.0218,  0.0750,  0.0716,  0.0721,  0.0263,  0.1027,\n",
       "                         0.1210,  0.1474,  0.1825,  0.0782,  0.0279,  0.0916,  0.1021,\n",
       "                         0.1346,  0.0294,  0.0120,  0.0652,  0.0555,  0.1072,  0.0644,\n",
       "                         0.0077, -0.0075],\n",
       "                       [ 0.0070,  0.1634,  0.0335,  0.0636, -0.0869,  0.1687, -0.0269,\n",
       "                        -0.0507, -0.0568, -0.1752,  0.1658,  0.1000,  0.0504,  0.0758,\n",
       "                        -0.0541,  0.2259, -0.2394, -0.0983, -0.2415, -0.5364,  0.1650,\n",
       "                        -0.0495, -0.0612, -0.1045, -0.1710,  0.1402,  0.0795, -0.0003,\n",
       "                         0.0346, -0.0507,  0.1535, -0.0539, -0.0851, -0.0788, -0.2375,\n",
       "                        -0.0007,  0.0138],\n",
       "                       [-0.0116, -0.0019,  0.0544,  0.0797,  0.1269, -0.1253,  0.0261,\n",
       "                        -0.0788,  0.0765,  0.0594,  0.1024,  0.1169,  0.1168,  0.0478,\n",
       "                         0.0032,  0.0568,  0.1358,  0.0828, -0.0271, -0.0838,  0.0466,\n",
       "                         0.0922,  0.0552, -0.0510, -0.3394, -0.0047, -0.0253, -0.0756,\n",
       "                        -0.1198, -0.3041, -0.2340,  0.2331,  0.2284,  0.0256,  0.7306,\n",
       "                         0.0413, -0.0117],\n",
       "                       [ 0.0445,  0.0021, -0.0149,  0.0915,  0.1762,  0.0228,  0.1648,\n",
       "                         0.1715,  0.1774,  0.1923, -0.0462, -0.0412, -0.0065,  0.1116,\n",
       "                         0.0584,  0.0291, -0.0674, -0.0846, -0.0285, -0.1179,  0.0444,\n",
       "                         0.0129,  0.0631,  0.2095,  0.3899,  0.2918, -0.0508, -0.1745,\n",
       "                        -0.2161, -0.5318, -0.0074, -0.1216, -0.1119,  0.0379, -0.1726,\n",
       "                         0.2423, -0.0401],\n",
       "                       [ 0.0202,  0.0309,  0.0456,  0.0539, -0.0041, -0.1286,  0.0484,\n",
       "                         0.0550,  0.1680,  0.1615, -0.0369,  0.0136,  0.0422,  0.0843,\n",
       "                         0.1239, -0.0423,  0.0514,  0.0145, -0.0022,  0.0780,  0.0209,\n",
       "                         0.0984,  0.0491,  0.0452, -0.0575, -0.0820,  0.0378,  0.0430,\n",
       "                         0.0829,  0.0491,  0.6251, -0.7212, -0.4614, -0.5403, -2.7278,\n",
       "                         0.0130,  0.0034]])),\n",
       "              ('hl.0.bias',\n",
       "               tensor([-0.0327,  0.1289,  0.0606,  0.0348, -0.0825, -0.0123,  0.0333,\n",
       "                        0.1811,  0.3821,  0.0320, -0.0945, -0.0355,  0.3284,  0.0092,\n",
       "                        0.1890, -0.0385, -0.0190, -0.0178])),\n",
       "              ('hl.1.weight',\n",
       "               tensor([[ 0.6552,  0.1637, -0.1923, -0.1075,  0.0637, -0.3024,  0.0252,\n",
       "                         0.1021,  0.0856, -0.0572, -0.2492,  0.5932,  0.1611, -0.2111,\n",
       "                         0.0427,  0.0415,  0.0129,  0.0225],\n",
       "                       [ 0.2964, -0.1109, -0.2302, -0.1821, -0.0028,  0.6788, -0.0766,\n",
       "                         0.1809,  0.1540, -0.0933,  0.4883, -0.4974,  0.3527, -0.0330,\n",
       "                         0.1373,  0.0372,  0.1725,  0.5652],\n",
       "                       [-0.4009, -0.2657,  0.2346,  0.0208, -0.0362,  0.1425,  0.0536,\n",
       "                        -0.2498,  0.1705,  0.0054,  0.1009,  0.6490, -0.0284, -0.3169,\n",
       "                        -0.0315, -0.0663, -0.1189, -0.8283],\n",
       "                       [ 0.7777, -0.2456, -0.2550, -0.2320,  0.2620,  0.3163,  0.2681,\n",
       "                         0.2737,  0.3657, -0.1418,  0.7046, -0.5368,  0.0148,  0.2369,\n",
       "                         0.1764,  0.2709,  0.1158,  0.6838],\n",
       "                       [-0.1813,  0.1990, -0.0591, -0.0627,  0.3558,  0.3714, -0.1670,\n",
       "                         0.1031, -0.0013, -0.3260,  0.1886,  0.2214, -0.0225,  0.0906,\n",
       "                         0.1602, -0.0774,  0.0560,  0.4888],\n",
       "                       [ 0.1492,  0.0889,  0.4243, -0.1462,  0.2117, -0.2555, -0.1615,\n",
       "                         0.0223, -0.0173, -0.1113, -0.4060,  0.3736, -0.1274, -0.5140,\n",
       "                        -0.1155,  0.0934, -0.1704, -0.1639],\n",
       "                       [ 0.5156, -0.0708, -0.2462, -0.1177, -0.0916,  0.8089,  0.1865,\n",
       "                         0.1178,  0.2318, -0.0252,  0.5184, -0.3057,  0.1753,  0.7935,\n",
       "                         0.1749,  0.1420,  0.1937,  0.5566],\n",
       "                       [-0.4359, -0.3240,  0.1547, -0.0887,  0.1118,  0.8616, -0.1216,\n",
       "                         0.2529,  0.0737,  0.2414,  0.4927,  0.0301,  0.1655,  0.1685,\n",
       "                         0.1528, -0.0987, -0.0573, -0.1794],\n",
       "                       [-0.6183,  0.2226,  0.1867,  0.1236, -0.0459, -0.5640, -0.2396,\n",
       "                        -0.0312,  0.0099, -0.0224, -0.3489,  0.1180, -0.0783,  0.5523,\n",
       "                         0.0120, -0.1114, -0.1182, -0.3856]])),\n",
       "              ('hl.1.bias',\n",
       "               tensor([ 0.0614,  0.4416,  0.0986,  0.3603, -0.0678,  0.1200,  0.1278,\n",
       "                        0.0214,  0.0964])),\n",
       "              ('output.weight',\n",
       "               tensor([[-0.2014,  0.2612, -0.0553,  0.4326, -0.5304, -0.3965,  0.5015,\n",
       "                         0.0708,  1.0160],\n",
       "                       [ 0.1407,  0.2420, -0.0547,  0.2945, -0.3848,  0.1286,  0.5621,\n",
       "                         0.2148,  1.0394],\n",
       "                       [ 0.3523,  0.2642, -0.0535,  0.5509,  0.1119, -0.3190,  0.2020,\n",
       "                        -0.2215,  0.4669],\n",
       "                       [-0.1285,  0.4966,  0.3899,  0.3867, -0.0043, -0.3984,  0.1698,\n",
       "                         0.5202,  0.3337]])),\n",
       "              ('output.bias', tensor([ 0.4031,  0.2138,  0.4344,  0.0539]))])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkpoint = torch.load('checkpoint.pth')\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_agent(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    agent = Agent(\n",
    "                  checkpoint['state_size'],\n",
    "                  checkpoint['action_size'],\n",
    "                  checkpoint['hidden_layers'],\n",
    "                  checkpoint['p'],\n",
    "                  checkpoint['seed'])\n",
    "\n",
    "    agent.qnetwork_target.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9e2fbd6d3488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#env = UnityEnvironment(file_name=\"./Banana_Linux/Banana.x86_64\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./Banana_Linux_NoVis/Banana.x86_64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;34m\"You may need to manually close a previously opened environment \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \"or use a different worker number.\".format(str(self.worker_id)))\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             raise UnityTimeOutException(\n\u001b[1;32m     60\u001b[0m                 \u001b[0;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"\"\"Whether there is any input available to be read\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_check_closed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"handle is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: handle is closed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/site-packages/grpc/_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\", line 25, in Exchange\n",
      "    self.child_conn.send(request)\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "#env = UnityEnvironment(file_name=\"./Banana_Linux/Banana.x86_64\")\n",
    "env = UnityEnvironment(file_name=\"./Banana_Linux_NoVis/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/site-packages/grpc/_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\", line 25, in Exchange\n",
      "    self.child_conn.send(request)\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/chuqui/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an agent with an already trained Q-Network\n",
    "agent = load_trained_agent('checkpoint.pth')\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "score = 0\n",
    "while True:\n",
    "    state = env_info.vector_observations[0]  # get the current state\n",
    "    action = agent.act(state)\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print('Score: {:.2f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
